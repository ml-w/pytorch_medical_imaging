[General]
use_cuda        = True
run_mode        = inference
run_type        = Segmentation
plot_tb         = True
fold_code       = B00
log_dir         = ./npc_segment.log
version         = 1.0
;force_train_data= No

# Controlled in main.py
[Checkpoint]
cp_load_dir = ./asset/trained_states/deeplearning/NPC_segment_v1.0.pt

# Controlled in main.py
[Network]
network_type = UNetLocTexHistDeeper(1, 1, fc_inchan=260)
; fc_chan needs to match [LoaderParam].patch_sampling_callback_kwargs['nbins'] * 2 + 4

# Controlled in solver/inferencer
[RunParams]
batch_size          = 40


# Controlled in main.py
[Data]
; if "", program ignores it
output_dir          = ""
input_dir           = ""

# Data loading filter, controlled by PMI_data_loader
[Filters]
re_suffix           = .*

# Controlled in PMI_data_loader
[LoaderParams]
PMI_datatype_name   = PMIImageDataLoader
data_types          = float-uint8
idGlobber           = [a-zA-Z0-9]+
patch_size          = [128, 128, 1]
sampler             = weighted
queue_kwargs        = {'max_length': 1500, 'samples_per_volume': 50}
augmentation        = ./asset/v1_seg_transform.yaml
; Put feature computed by callback `loc_test_hist` into key 'feature' of the subject
patch_sampling_callback         = loc_text_hist
patch_sampling_callback_kwargs  = {'nbins':128, 'include':'input'}
create_new_attribute            = feature
inf_samples_per_vol = 550

[SolverParams]
unpack_keys_forward = [('input', 'feature'), 'gt']
unpack_keys_inf     = ['input', 'feature']
gt_keys             = ['gt']
sigmoid_params      = {'delay': 5, 'stretch':1, 'cap': 0.2}
; If probmap available, use weighted sampler for inference.
;class [null, thickening, cyst]
class_weights       = [0.01, 1.0]
optimizer_type      = Adam
initial_weight      = 1
learning_rate       = 1E-3
momentum            = 0.95
num_of_epochs       = 1
decay_rate_LR       = 1
decay_on_plateau    = False
lr_scheduler_dict   = {'cooldown':100, 'patience':50}

